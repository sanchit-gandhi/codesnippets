{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d03f1ec8-3ca3-4edc-9c99-c6bae9177387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set JAX platform to CPU for highest matmul precision\n",
    "import os\n",
    "#os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d71739-61a0-470d-9b17-2e4a60c21530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanchitgandhi/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import FlaxBloomForCausalLM, BloomForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9738731-61f3-49fc-86e5-0b36ee6249a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some of the weights of FlaxBloomForCausalLM were initialized in float16 precision from the model checkpoint at bigscience/bloom-350m:\n",
      "[('transformer', 'h', '0', 'input_layernorm', 'bias'), ('transformer', 'h', '0', 'input_layernorm', 'scale'), ('transformer', 'h', '0', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '0', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '0', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '0', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '0', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '0', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '0', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '0', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '0', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '0', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '1', 'input_layernorm', 'bias'), ('transformer', 'h', '1', 'input_layernorm', 'scale'), ('transformer', 'h', '1', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '1', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '1', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '1', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '1', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '1', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '1', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '1', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '1', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '1', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '10', 'input_layernorm', 'bias'), ('transformer', 'h', '10', 'input_layernorm', 'scale'), ('transformer', 'h', '10', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '10', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '10', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '10', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '10', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '10', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '10', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '10', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '10', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '10', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '11', 'input_layernorm', 'bias'), ('transformer', 'h', '11', 'input_layernorm', 'scale'), ('transformer', 'h', '11', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '11', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '11', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '11', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '11', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '11', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '11', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '11', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '11', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '11', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '12', 'input_layernorm', 'bias'), ('transformer', 'h', '12', 'input_layernorm', 'scale'), ('transformer', 'h', '12', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '12', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '12', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '12', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '12', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '12', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '12', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '12', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '12', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '12', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '13', 'input_layernorm', 'bias'), ('transformer', 'h', '13', 'input_layernorm', 'scale'), ('transformer', 'h', '13', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '13', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '13', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '13', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '13', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '13', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '13', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '13', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '13', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '13', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '14', 'input_layernorm', 'bias'), ('transformer', 'h', '14', 'input_layernorm', 'scale'), ('transformer', 'h', '14', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '14', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '14', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '14', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '14', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '14', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '14', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '14', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '14', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '14', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '15', 'input_layernorm', 'bias'), ('transformer', 'h', '15', 'input_layernorm', 'scale'), ('transformer', 'h', '15', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '15', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '15', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '15', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '15', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '15', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '15', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '15', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '15', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '15', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '16', 'input_layernorm', 'bias'), ('transformer', 'h', '16', 'input_layernorm', 'scale'), ('transformer', 'h', '16', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '16', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '16', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '16', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '16', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '16', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '16', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '16', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '16', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '16', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '17', 'input_layernorm', 'bias'), ('transformer', 'h', '17', 'input_layernorm', 'scale'), ('transformer', 'h', '17', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '17', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '17', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '17', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '17', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '17', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '17', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '17', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '17', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '17', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '18', 'input_layernorm', 'bias'), ('transformer', 'h', '18', 'input_layernorm', 'scale'), ('transformer', 'h', '18', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '18', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '18', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '18', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '18', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '18', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '18', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '18', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '18', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '18', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '19', 'input_layernorm', 'bias'), ('transformer', 'h', '19', 'input_layernorm', 'scale'), ('transformer', 'h', '19', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '19', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '19', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '19', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '19', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '19', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '19', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '19', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '19', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '19', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '2', 'input_layernorm', 'bias'), ('transformer', 'h', '2', 'input_layernorm', 'scale'), ('transformer', 'h', '2', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '2', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '2', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '2', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '2', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '2', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '2', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '2', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '2', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '2', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '20', 'input_layernorm', 'bias'), ('transformer', 'h', '20', 'input_layernorm', 'scale'), ('transformer', 'h', '20', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '20', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '20', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '20', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '20', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '20', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '20', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '20', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '20', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '20', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '21', 'input_layernorm', 'bias'), ('transformer', 'h', '21', 'input_layernorm', 'scale'), ('transformer', 'h', '21', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '21', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '21', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '21', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '21', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '21', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '21', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '21', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '21', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '21', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '22', 'input_layernorm', 'bias'), ('transformer', 'h', '22', 'input_layernorm', 'scale'), ('transformer', 'h', '22', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '22', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '22', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '22', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '22', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '22', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '22', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '22', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '22', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '22', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '23', 'input_layernorm', 'bias'), ('transformer', 'h', '23', 'input_layernorm', 'scale'), ('transformer', 'h', '23', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '23', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '23', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '23', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '23', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '23', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '23', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '23', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '23', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '23', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '3', 'input_layernorm', 'bias'), ('transformer', 'h', '3', 'input_layernorm', 'scale'), ('transformer', 'h', '3', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '3', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '3', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '3', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '3', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '3', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '3', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '3', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '3', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '3', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '4', 'input_layernorm', 'bias'), ('transformer', 'h', '4', 'input_layernorm', 'scale'), ('transformer', 'h', '4', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '4', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '4', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '4', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '4', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '4', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '4', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '4', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '4', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '4', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '5', 'input_layernorm', 'bias'), ('transformer', 'h', '5', 'input_layernorm', 'scale'), ('transformer', 'h', '5', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '5', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '5', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '5', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '5', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '5', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '5', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '5', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '5', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '5', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '6', 'input_layernorm', 'bias'), ('transformer', 'h', '6', 'input_layernorm', 'scale'), ('transformer', 'h', '6', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '6', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '6', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '6', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '6', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '6', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '6', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '6', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '6', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '6', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '7', 'input_layernorm', 'bias'), ('transformer', 'h', '7', 'input_layernorm', 'scale'), ('transformer', 'h', '7', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '7', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '7', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '7', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '7', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '7', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '7', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '7', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '7', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '7', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '8', 'input_layernorm', 'bias'), ('transformer', 'h', '8', 'input_layernorm', 'scale'), ('transformer', 'h', '8', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '8', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '8', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '8', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '8', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '8', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '8', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '8', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '8', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '8', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '9', 'input_layernorm', 'bias'), ('transformer', 'h', '9', 'input_layernorm', 'scale'), ('transformer', 'h', '9', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '9', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '9', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '9', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '9', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '9', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '9', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '9', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '9', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '9', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'ln_f', 'bias'), ('transformer', 'ln_f', 'scale'), ('transformer', 'word_embeddings', 'embedding'), ('transformer', 'word_embeddings_layernorm', 'bias'), ('transformer', 'word_embeddings_layernorm', 'scale')]\n",
      "You should probably UPCAST the model weights to float32 if this was not intended. See [`~FlaxPreTrainedModel.to_fp32`] for further information on how to do this.\n"
     ]
    }
   ],
   "source": [
    "#model_id = \"bigscience/bigscience-small-testing\"\n",
    "model_id = \"bigscience/bloom-350m\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-350m\")\n",
    "\n",
    "pt_model = BloomForCausalLM.from_pretrained(model_id)\n",
    "flax_model = FlaxBloomForCausalLM.from_pretrained(model_id, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f18a5b-2b5f-4487-b8c0-ae6302557d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "input_str = [10*\"hello this string is definitely longer\", \"Hey you\"]\n",
    "\n",
    "inputs_pt = tokenizer(input_str, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "inputs_np = tokenizer(input_str, return_tensors=\"np\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07d646a-ae15-4057-ab23-8f94f40b0e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits_pt = pt_model(**inputs_pt).logits\n",
    "    logits_pt_single = pt_model(inputs_pt.input_ids[:1]).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d780c61e-696b-45e4-b47b-f85bff466710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 13:22:48.113268: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched padded pt vs padded flax\n",
      "1.8187866\n",
      "batched full pt vs full flax\n",
      "4.13562\n",
      "single pt vs flax\n",
      "5.2735596\n",
      "single flax vs flax\n",
      "2.4197693\n"
     ]
    }
   ],
   "source": [
    "# default matmul precision (bfloat16)\n",
    "logits_fx = flax_model(**inputs_np).logits\n",
    "logits_fx_single = flax_model(inputs_np.input_ids[:1]).logits\n",
    "\n",
    "print(\"batched padded pt vs padded flax\")\n",
    "print(np.max(np.abs(logits_pt[1, :2].numpy() - np.array(logits_fx[1, :2]))))\n",
    "\n",
    "print(\"batched full pt vs full flax\")\n",
    "print(np.max(np.abs(logits_pt[0].numpy() - np.array(logits_fx[0]))))\n",
    "\n",
    "print(\"single pt vs flax\")\n",
    "print(np.max(np.abs(logits_pt_single[0].numpy() - np.array(logits_fx_single[0]))))\n",
    "\n",
    "print(\"single flax vs flax\")\n",
    "print(np.max(np.abs(np.array(logits_fx[0]) - np.array(logits_fx_single[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5b30af3-6948-453d-8810-7982c858d0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched padded pt vs padded flax\n",
      "0.0032348633\n",
      "batched full pt vs full flax\n",
      "0.0056152344\n",
      "single pt vs flax\n",
      "0.0048828125\n",
      "single flax vs flax\n",
      "0.00036621094\n"
     ]
    }
   ],
   "source": [
    "# highest matmul precision (float32)\n",
    "with jax.default_matmul_precision('float32'):\n",
    "    logits_fx = flax_model(**inputs_np).logits\n",
    "    logits_fx_single = flax_model(inputs_np.input_ids[:1]).logits\n",
    "    \n",
    "print(\"batched padded pt vs padded flax\")\n",
    "print(np.max(np.abs(logits_pt[1, :2].numpy() - np.array(logits_fx[1, :2]))))\n",
    "\n",
    "print(\"batched full pt vs full flax\")\n",
    "print(np.max(np.abs(logits_pt[0].numpy() - np.array(logits_fx[0]))))\n",
    "\n",
    "print(\"single pt vs flax\")\n",
    "print(np.max(np.abs(logits_pt_single[0].numpy() - np.array(logits_fx_single[0]))))\n",
    "\n",
    "print(\"single flax vs flax\")\n",
    "print(np.max(np.abs(np.array(logits_fx[0]) - np.array(logits_fx_single[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0769a6da-d641-4367-9f65-2e0852c88c2b",
   "metadata": {},
   "source": [
    "## JIT the fprop and watch the magic happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80292b8d-734a-4d17-8a6c-3e3a3fd18aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def flax_model_jitted(input_ids, attention_mask=None, **kwargs):\n",
    "    return flax_model(input_ids, attention_mask=attention_mask, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb44ed-08b1-45c0-b52a-5975465da054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 2237095936 bytes == 0x29d86a000 @  0x7fbbe9d99680 0x7fbbe9dba824 0x58f8b8 0x586650 0x5869d4 0x619464 0x6194c2 0x6213b0 0x62177a 0x5c47d0 0x5f6517 0x7fba62077bf1 0x7fba618dab27 0x7fba61ab56a6 0x7fba619d1c46 0x7fba619d1f77 0x7fba619d833d 0x7fba619d8e80 0x7fba61a500b0 0x7fba619d9197 0x7fba619d9a5b 0x7fba619da21b 0x7fba61a3b5e6 0x7fba618ebfab 0x7fba618ec2a6 0x7fba619d9197 0x7fba619d9a5b 0x7fba619da21b 0x7fba61a1096d 0x7fba61a109c6 0x7fba619d9197\n",
      "tcmalloc: large alloc 2237431808 bytes == 0x1e5272000 @  0x7fbbe9d99680 0x7fbbe9dba824 0x58f8b8 0x586650 0x5869d4 0x619464 0x6195b6 0x6217b3 0x5042cb 0x56b1da 0x5f6836 0x570035 0x5f6836 0x56b0ae 0x56939a 0x5f6a13 0x5f3547 0x56c8cd 0x5f6836 0x56b1da 0x56939a 0x5f6a13 0x5f3547 0x56c8cd 0x56939a 0x5f6a13 0x5f3547 0x56c8cd 0x56939a 0x5f6a13 0x5f3547\n",
      "tcmalloc: large alloc 2237431808 bytes == 0x29d86a000 @  0x7fbbe9d99680 0x7fbbe9db9ff4 0x7fba794cd1de 0x7fba794cf979 0x7fba79505533 0x7fba794e4991 0x5f3989 0x5f3e1e 0x50b183 0x56c28c 0x5f6836 0x5f3547 0x56c8cd 0x56939a 0x5f6a13 0x56b0ae 0x5f6836 0x56b0ae 0x56939a 0x5f6a13 0x5f3547 0x56c8cd 0x5f6836 0x56b1da 0x56939a 0x5f6a13 0x5f3547 0x56c8cd 0x56939a 0x5f6a13 0x5f3547\n",
      "tcmalloc: large alloc 2751438848 bytes == 0x594452000 @  0x7fbbe9d99680 0x7fbbe9db9ff4 0x7fba7d2b78ca 0x7fba7c588cb7 0x7fba7c57ee17 0x7fba7c578249 0x7fba7b6bf611 0x7fba7b6cdad0 0x7fba7971feaa 0x7fba79504f56 0x7fba79505597 0x7fba794e4991 0x5f3989 0x5f3e1e 0x50b183 0x56c28c 0x5f6836 0x5f3547 0x56c8cd 0x56939a 0x5f6a13 0x56b0ae 0x5f6836 0x56b0ae 0x56939a 0x5f6a13 0x5f3547 0x56c8cd 0x5f6836 0x56b1da 0x56939a\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/message_lite.cc:484] xla.HloModuleProto exceeded maximum protobuf size of 2GB: 2751431778\n",
      "2022-07-06 13:25:19.876073: F external/org_tensorflow/tensorflow/stream_executor/tpu/proto_helper.h:44] Check failed: proto.SerializeToArray(bytes, size) \n",
      "https://symbolize.stripped_domain/r/?trace=7fbbe9bca03b,7fbbe9bca0bf,7fba793a41ec,7fba793a45cf,7fba7c588cb6,7fba7c57ee16,7fba7c578248,7fba7b6bf610,7fba7b6cdacf,7fba7971fea9,7fba79504f55,7fba79505596,7fba794e4990,5f3988,903aff&map= \n",
      "*** SIGABRT received by PID 656516 (TID 656516) on cpu 53 from PID 656516; stack trace: ***\n",
      "PC: @     0x7fbbe9bca03b  (unknown)  raise\n",
      "    @     0x7fba78125c73        992  (unknown)\n",
      "    @     0x7fbbe9bca0c0  (unknown)  (unknown)\n",
      "    @     0x7fba793a41ed        432  stream_executor::tpu::SerializeProto<>()\n",
      "    @     0x7fba793a45d0       3440  xla::(anonymous namespace)::TpuCompiler::RunHloPasses()\n",
      "    @     0x7fba7c588cb7        608  xla::Service::BuildExecutable()\n",
      "    @     0x7fba7c57ee17       1152  xla::LocalService::CompileExecutables()\n",
      "    @     0x7fba7c578249       2672  xla::LocalClient::Compile()\n",
      "    @     0x7fba7b6bf611        896  xla::PjRtStreamExecutorClient::Compile()\n",
      "    @     0x7fba7b6cdad0       1216  xla::PjRtStreamExecutorClient::Compile()\n",
      "    @     0x7fba7971feaa       1168  xla::PyClient::CompileMlir()\n",
      "    @     0x7fba79504f56       1888  pybind11::detail::argument_loader<>::call_impl<>()\n",
      "    @     0x7fba79505597        208  pybind11::cpp_function::initialize<>()::{lambda()#3}::_FUN()\n",
      "    @     0x7fba794e4991        768  pybind11::cpp_function::dispatcher()\n",
      "    @           0x5f3989  (unknown)  PyCFunction_Call\n",
      "    @           0x903b00  (unknown)  (unknown)\n",
      "https://symbolize.stripped_domain/r/?trace=7fbbe9bca03b,7fba78125c72,7fbbe9bca0bf,7fba793a41ec,7fba793a45cf,7fba7c588cb6,7fba7c57ee16,7fba7c578248,7fba7b6bf610,7fba7b6cdacf,7fba7971fea9,7fba79504f55,7fba79505596,7fba794e4990,5f3988,903aff&map=abc33f1bfca16f4e7d925d4248b4beb3:7fba639f7000-7fba784a6b70 \n",
      "E0706 13:25:19.962431  656516 coredump_hook.cc:366] RAW: Remote crash data gathering hook invoked.\n",
      "E0706 13:25:19.962446  656516 coredump_hook.cc:412] RAW: Skipping coredump since rlimit was 0 at process start.\n",
      "E0706 13:25:19.962453  656516 client.cc:234] RAW: Coroner client retries enabled (b/136286901), will retry for up to 30 sec.\n",
      "E0706 13:25:19.962456  656516 coredump_hook.cc:473] RAW: Sending fingerprint to remote end.\n",
      "E0706 13:25:19.962463  656516 coredump_socket.cc:118] RAW: Stat failed errno=2 on socket /var/google/services/logmanagerd/remote_coredump.socket\n",
      "E0706 13:25:19.962470  656516 coredump_hook.cc:477] RAW: Cannot send fingerprint to Coroner: [NOT_FOUND] Missing crash reporting socket. Is the listener running?\n",
      "E0706 13:25:19.962474  656516 coredump_hook.cc:551] RAW: Discarding core.\n"
     ]
    }
   ],
   "source": [
    "# microbench jit compile time for batch\n",
    "%time logits_fx = flax_model_jitted(**inputs_np).logits.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45ce7a-625b-47a8-acf5-a678170020eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# microbench compiled fprop -> should be ~ms, if on the order of seconds inidicates a recompilation\n",
    "%time logits_fx = flax_model_jitted(**inputs_np).logits.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd67dc-868c-42f9-88b9-814e3b06cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# microbench jit compile time for single input\n",
    "%time logits_fx_single = flax_model_jitted(inputs_np.input_ids[:1]).logits.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d244938-3d66-4a5f-8bfb-e6ed6328fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# microbench compiled fprop for single input -> should be ~ms, if on the order of seconds inidicates a recompilation\n",
    "%time logits_fx_single = flax_model_jitted(inputs_np.input_ids[:1]).logits.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57134e64-16c4-4539-a4cd-5b18b86a70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify correctness of jit-compiled fprop\n",
    "print(\"batched padded pt vs padded flax\")\n",
    "print(np.max(np.abs(logits_pt[1, :2].numpy() - np.array(logits_fx[1, :2]))))\n",
    "\n",
    "print(\"batched full pt vs full flax\")\n",
    "print(np.max(np.abs(logits_pt[0].numpy() - np.array(logits_fx[0]))))\n",
    "\n",
    "print(\"single pt vs flax\")\n",
    "print(np.max(np.abs(logits_pt_single[0].numpy() - np.array(logits_fx_single[0]))))\n",
    "\n",
    "print(\"single flax vs flax\")\n",
    "print(np.max(np.abs(np.array(logits_fx[0]) - np.array(logits_fx_single[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ccb1b-4ed0-4cd9-abbb-0040c2e2cf2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
