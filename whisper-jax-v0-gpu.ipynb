{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper JAX ⚡️\n",
    "\n",
    "This Kaggle notebook demonstratese how to run Whisper JAX on a Colab GPU. Whisper JAX is a highly optimised JAX implementation of the Whisper model by OpenAI, largely built on the 🤗 Hugging Face Transformers Whisper implementation. Compared to OpenAI's PyTorch code, Whisper JAX runs over **70x faster**, making it the fastest Whisper implementation available.\n",
    "\n",
    "The Whisper JAX model is also running as a [demo](https://huggingface.co/spaces/sanchit-gandhi/whisper-jax) on the Hugging Face Hub. You can also try it on a Kaggle TPU with the following [notebook](TODO), which will yield faster results than on a Colab GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure we're connected to a GPU to run this notebook. To get a GPU, click _Runtime_ -> _Change runtime type_, then change Hardware accelerator from _None_ to _GPU_. We can verify that we've been assigned a GPU and view its specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 19 15:16:12 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0    37W / 300W |  12553MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     27194      C   ...vs/jax-flax/bin/python3.9    12551MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that we've got on Tesla V100 16GB GPU with CUDA version 11.6. We'll need to install the corresponding verison of JAX to match this CUDA version. If you have CUDA version 12, you should replace `cuda11` with `cuda12` in the following code cell. \n",
    "\n",
    "Should you encounter any difficulties installing JAX, refer to the official [JAX installation guide](https://github.com/google/jax#pip-installation-gpu-cuda-installed-via-pip-easier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet pip\n",
    "\n",
    "# CUDA 11 installation\n",
    "# Note: wheels only available on linux.\n",
    "!pip install --upgrade --quiet \"jax[cuda11_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the hardest part out the way! We can then install the remaining Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --quiet git+https://github.com/sanchit-gandhi/whisper-jax.git datasets soundfile librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that our GPU is registered with JAX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 JAX devices of type Tesla V100-SXM2-16GB.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "num_devices = jax.device_count()\n",
    "device_type = jax.devices()[0].device_kind\n",
    "\n",
    "print(f\"Found {num_devices} JAX devices of type {device_type}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We've got 1 Tesla V100 GPU registered with JAX. This matches what we saw with `nvidia-smi` from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Pipeline\n",
    "\n",
    "The recommended way of running Whisper JAX is through the [`FlaxWhisperPipline`](https://github.com/sanchit-gandhi/whisper-jax/blob/main/whisper_jax/pipeline.py#L57) class. This class handles all the necessary pre- and post-processing for the model, as well as wrapping the generate method for data parallelism across all available accelerator devices.\n",
    "\n",
    "Whisper JAX makes use of JAX's [`pmap`](https://jax.readthedocs.io/en/latest/_autosummary/jax.pmap.html) function for data parallelism across GPU/TPU devices. This function is Just In Time (JIT) compiled the first time it is called. Thereafter, the function will be cached, enabling it to be run in super-fast time.\n",
    "\n",
    "\n",
    "Let's load the large-v2 model in float16 (half-precision). Using half-precision will speed-up the computation quite considerably by storing intermediate tensors in half-precision. There is no change to the precision of the model weights.\n",
    "\n",
    "We'll also make use of _batching_ for single audio inputs: the audio is first chunked into 30 second segments, and then chunks dispatched to the model to be transcribed in parallel. By batching an audio input and transcribing it in parallel, we get a ~10x speed-up compared to transcribing the audio samples sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████████████████████████████████████| 1.98k/1.98k [00:00<00:00, 218kB/s]\n",
      "Downloading (…)flax_model.msgpack\";: 100%|███████████████████████████████████████████| 151M/151M [00:04<00:00, 35.7MB/s]\n",
      "2023-04-19 15:17:04.752276: E external/xla/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.2.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwhisper_jax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlaxWhisperPipline\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mFlaxWhisperPipline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenai/whisper-tiny\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/whisper_jax/pipeline.py:88\u001b[0m, in \u001b[0;36mFlaxWhisperPipline.__init__\u001b[0;34m(self, checkpoint, dtype, batch_size, max_length)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mfeature_extractor\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mtokenizer\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m \u001b[43mFlaxWhisperForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_do_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m max_length \u001b[38;5;28;01mif\u001b[39;00m max_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_batch_size \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlocal_device_count()\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/transformers/modeling_flax_utils.py:807\u001b[0m, in \u001b[0;36mFlaxPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, dtype, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m     resolved_archive_file, _ \u001b[38;5;241m=\u001b[39m get_checkpoint_shard_files(\n\u001b[1;32m    792\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    793\u001b[0m         resolved_archive_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    803\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m    804\u001b[0m     )\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# init random models\u001b[39;00m\n\u001b[0;32m--> 807\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_do_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_pt:\n\u001b[1;32m    810\u001b[0m     state \u001b[38;5;241m=\u001b[39m load_pytorch_checkpoint_in_flax_state_dict(model, resolved_archive_file, is_sharded)\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/whisper_jax/modeling_flax_whisper.py:1008\u001b[0m, in \u001b[0;36mFlaxWhisperPreTrainedModel.__init__\u001b[0;34m(self, config, input_shape, seed, dtype, params_dtype, _do_init, **kwargs)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    999\u001b[0m     config: WhisperConfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1006\u001b[0m ):\n\u001b[1;32m   1007\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_class(config\u001b[38;5;241m=\u001b[39mconfig, dtype\u001b[38;5;241m=\u001b[39mdtype, params_dtype\u001b[38;5;241m=\u001b[39mparams_dtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_do_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/transformers/modeling_flax_utils.py:199\u001b[0m, in \u001b[0;36mFlaxPreTrainedModel.__init__\u001b[0;34m(self, config, module, input_shape, seed, dtype, _do_init)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Those are public as their type is generic to every derived classes.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m \u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_shape \u001b[38;5;241m=\u001b[39m input_shape\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/random.py:136\u001b[0m, in \u001b[0;36mPRNGKey\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(seed):\n\u001b[1;32m    134\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRNGKey accepts a scalar seed, but was given an array of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(seed)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != (). Use jax.vmap for batching\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 136\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43mprng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed_with_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _return_prng_keys(\u001b[38;5;28;01mTrue\u001b[39;00m, key)\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/prng.py:270\u001b[0m, in \u001b[0;36mseed_with_impl\u001b[0;34m(impl, seed)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mseed_with_impl\u001b[39m(impl: PRNGImpl, seed: Union[\u001b[38;5;28mint\u001b[39m, Array]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PRNGKeyArray:\n\u001b[0;32m--> 270\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/prng.py:561\u001b[0m, in \u001b[0;36mrandom_seed\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m   seeds_arr \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39masarray(seeds)\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_seed_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseeds_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/core.py:360\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    358\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_enable_checks \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    359\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[0;32m--> 360\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/core.py:363\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 363\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/core.py:817\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 817\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/prng.py:573\u001b[0m, in \u001b[0;36mrandom_seed_impl\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;129m@random_seed_p\u001b[39m\u001b[38;5;241m.\u001b[39mdef_impl\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_seed_impl\u001b[39m(seeds, \u001b[38;5;241m*\u001b[39m, impl):\n\u001b[0;32m--> 573\u001b[0m   base_arr \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_seed_impl_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m PRNGKeyArray(impl, base_arr)\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/prng.py:578\u001b[0m, in \u001b[0;36mrandom_seed_impl_base\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_seed_impl_base\u001b[39m(seeds, \u001b[38;5;241m*\u001b[39m, impl):\n\u001b[1;32m    577\u001b[0m   seed \u001b[38;5;241m=\u001b[39m iterated_vmap_unary(seeds\u001b[38;5;241m.\u001b[39mndim, impl\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m--> 578\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/prng.py:813\u001b[0m, in \u001b[0;36mthreefry_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    810\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRNG key seed must be an integer; got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    811\u001b[0m convert \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m k: lax\u001b[38;5;241m.\u001b[39mreshape(lax\u001b[38;5;241m.\u001b[39mconvert_element_type(k, np\u001b[38;5;241m.\u001b[39muint32), [\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    812\u001b[0m k1 \u001b[38;5;241m=\u001b[39m convert(\n\u001b[0;32m--> 813\u001b[0m     \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift_right_logical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlax_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_const\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnumpy_dtype_promotion(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    815\u001b[0m   \u001b[38;5;66;03m# TODO(jakevdp): in X64 mode, this can generate 64-bit computations for 32-bit\u001b[39;00m\n\u001b[1;32m    816\u001b[0m   \u001b[38;5;66;03m# inputs. We should avoid this.\u001b[39;00m\n\u001b[1;32m    817\u001b[0m   k2 \u001b[38;5;241m=\u001b[39m convert(jnp\u001b[38;5;241m.\u001b[39mbitwise_and(seed, np\u001b[38;5;241m.\u001b[39muint32(\u001b[38;5;241m0xFFFFFFFF\u001b[39m)))\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/lax/lax.py:458\u001b[0m, in \u001b[0;36mshift_right_logical\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshift_right_logical\u001b[39m(x: ArrayLike, y: ArrayLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m    457\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Elementwise logical right shift: :math:`x \\gg y`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshift_right_logical_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/core.py:360\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    358\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_enable_checks \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    359\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[0;32m--> 360\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/core.py:363\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 363\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/core.py:817\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 817\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/dispatch.py:117\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pjit\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m   compiled_fun \u001b[38;5;241m=\u001b[39m \u001b[43mxla_primitive_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munsafe_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pxla\u001b[38;5;241m.\u001b[39mDeviceAssignmentMismatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m   fails, \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39margs\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/util.py:253\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trace_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/util.py:246\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.cached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(max_size)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached\u001b[39m(_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 246\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/dispatch.py:208\u001b[0m, in \u001b[0;36mxla_primitive_callable\u001b[0;34m(prim, *arg_specs, **params)\u001b[0m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out,\n\u001b[0;32m--> 208\u001b[0m compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_xla_callable_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprim_fun\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg_specs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prim\u001b[38;5;241m.\u001b[39mmultiple_results:\n\u001b[1;32m    211\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: compiled(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/dispatch.py:254\u001b[0m, in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, name, donated_invars, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    251\u001b[0m computation \u001b[38;5;241m=\u001b[39m sharded_lowering(fun, name, donated_invars, keep_unused,\n\u001b[1;32m    252\u001b[0m                                \u001b[38;5;241m*\u001b[39marg_specs, lowering_platform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    253\u001b[0m allow_prop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(computation\u001b[38;5;241m.\u001b[39mcompile_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_out_avals\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomputation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_allow_propagation_to_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_prop\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsafe_call\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/interpreters/pxla.py:2816\u001b[0m, in \u001b[0;36mMeshComputation.compile\u001b[0;34m(self, _allow_propagation_to_outputs, _allow_compile_replicated)\u001b[0m\n\u001b[1;32m   2813\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executable \u001b[38;5;241m=\u001b[39m MeshExecutable\u001b[38;5;241m.\u001b[39mfrom_trivial_jaxpr(\n\u001b[1;32m   2814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile_args)\n\u001b[1;32m   2815\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2816\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executable \u001b[38;5;241m=\u001b[39m \u001b[43mUnloadedMeshExecutable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_hlo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hlo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_allow_propagation_to_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_allow_propagation_to_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_allow_compile_replicated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_allow_compile_replicated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executable\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/interpreters/pxla.py:3028\u001b[0m, in \u001b[0;36mUnloadedMeshExecutable.from_hlo\u001b[0;34m(name, computation, mesh, global_in_avals, global_out_avals, in_shardings, out_shardings, spmd_lowering, tuple_args, auto_spmd_lowering, _allow_propagation_to_outputs, _allow_compile_replicated, unordered_effects, ordered_effects, host_callbacks, keepalive, kept_var_idx, backend, device_assignment, committed, pmap_nreps)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mlog_elapsed_time(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished XLA compilation of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3026\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min \u001b[39m\u001b[38;5;132;01m{elapsed_time}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3027\u001b[0m                                  event\u001b[38;5;241m=\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mBACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 3028\u001b[0m     xla_executable \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_or_get_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3031\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m auto_spmd_lowering:\n\u001b[1;32m   3032\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m mesh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/dispatch.py:526\u001b[0m, in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, compile_options, host_callbacks)\u001b[0m\n\u001b[1;32m    522\u001b[0m     _cache_write(serialized_computation, compile_time, module_name,\n\u001b[1;32m    523\u001b[0m                  compile_options, backend, compiled, host_callbacks)\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compiled\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialized_computation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/opt/conda/envs/jax-flax/lib/python3.9/site-packages/jax/_src/dispatch.py:471\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options, host_callbacks)\u001b[0m\n\u001b[1;32m    466\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(built_c, compile_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    467\u001b[0m                          host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details."
     ]
    }
   ],
   "source": [
    "from whisper_jax import FlaxWhisperPipline\n",
    "import jax.numpy as jnp\n",
    "\n",
    "pipeline = FlaxWhisperPipline(\"openai/whisper-large-v2\", dtype=jnp.float16, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then initialise a compilation cache, which will speed-up the compilation time if we close our kernel and want to compile the model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized persistent compilation cache at ./jax_cache\n"
     ]
    }
   ],
   "source": [
    "from jax.experimental.compilation_cache import compilation_cache as cc\n",
    "\n",
    "cc.initialize_cache(\"./jax_cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎶 Load an audio file\n",
    "\n",
    "Let's load up a long audio file for our tests. We provide 5 and 30 mins audio files created by contatenating consecutive sample of the [LibriSpeech ASR](https://huggingface.co/datasets/librispeech_asr) corpus, which we can load in one line through Hugging Face Datastes' [`load_dataset`](https://huggingface.co/docs/datasets/loading#load) function. Note that you can also pass in any `.mp3`, `.wav` or `.flac` audio file directly to the Whisper JAX pipeline, and it will take care of loading the audio file for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/sanchitgandhi/.cache/huggingface/datasets/sanchit-gandhi___parquet/sanchit-gandhi--whisper-jax-test-files-95479fe55e88baac/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test_dataset = load_dataset(\"sanchit-gandhi/whisper-jax-test-files\", split=\"train\")\n",
    "audio = test_dataset[0][\"audio\"]  # load the first sample (5 mins) and get the audio array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a listen to the audio file that we've loaded, you'll see that it's approximately 5 mins long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(audio[\"array\"], rate=audio[\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model\n",
    "\n",
    "Now we're ready to transcribe! We'll need to compile the `pmap` function the first time we use it. You can expect compilation to take ~2 minutes on a TPU v3-8 with a batch size of 16. Enough time to grab a coffee ☕️\n",
    "\n",
    "Thereafter, we can use our cached `pmap` function, which you'll see is amazingly fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 18s, sys: 7min 53s, total: 12min 12s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "# JIT compile the forward call - slow, but we only do once\n",
    "%time text = pipeline(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 39.5 s, total: 52.2 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "# used cached function thereafter - super fast!\n",
    "%time text = pipeline(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \" Chapter 16. I might have told you of the beginning of this liaison in a few lines, but I wanted you to see every step by which we came, I to agree to whatever Marguerite wished, Marguerite to be unable to live apart from me. It was the day after the evening when she came to see me that I sent her Manon Lescate. From that time, seeing that I could not change my mistress's life, I changed my own. I wished above all not to leave myself time to think over the position I had accepted, for, in spite of myself, it was a great distress to me. Thus my life, generally so calm, assumed all at once an appearance of noise and disorder. Never believe, however disinterested the love of a kept woman may be, that it will cost one nothing. Nothing is so expensive as their caprices, flowers, boxes at the theatre, suppers, days in the country, which one can never refuse to one's mistress. As I have told you, I had little money. My father was, and still is, Receiver General at sea. He has a great reputation there for loyalty, thanks to which he was able to find the security which he needed in order to attain this position. I came to Paris, studied law, was called to the bar, and, like many other young men, put my diploma in my pocket, and let myself drift, as one so easily does in Paris. My expenses were very moderate, only I used up my year's income in eight months, and spent the four summer months with my father, which practically gave me twelve thousand francs a year, and, in addition, the reputation of a good son. For the rest, not a penny of debt. This, then, was my position when I made the acquaintance of Marguerite. You can well understand that, in spite of myself, my expenses soon increased. Marguerite's nature was very capricious, and, like so many women, she never regarded as a serious expense those thousand and one distractions which made up her life. So, wishing to spend as much time with me as possible, she would write to me in the morning that she would dine with me, not at home, but at some restaurant in Paris, or in the country. I would call for her, and we would dine and go on to the theatre, often having supper as well. Forgive me if I give you all these details, but you will see that they were the cause of what was to follow. What I tell you is a true and simple story, and I leave to it all the naivete of its details, and all the simplicity of its developments. I realized then that as nothing in the world would make me forget my mistress, it was needful for me to find some way of meeting the expenses into which she drew me. Then, too, my love for her had so disturbing an influence upon me, that every moment I spent away from Marguerite was like a year, and that I felt the need of consuming these moments in the fire of some sort of passion, as not to know that I was living them. I began by borrowing five or six thousand francs on my little capital, and with this I took to gambling. Since gambling-houses were destroyed, gambling goes on everywhere. Formerly, when one went to Frascati, one had the chance of making a fortune, one played against money, and if one lost, there was always the consolation of saying that one might have gained. Whereas now, except in the clubs, where there is still a certain rigour in regard to payments, one is almost certain, the moment one gains a considerable sum, not to receive it. You will readily understand why. Gambling is only likely to be carried on by young people very much in need of money, and not possessing the fortune necessary for supporting the life they lead. They gamble, then, and with this result, or else they gain, and then those who lose serve to pay for their horses and mistresses, which is very disagreeable. Debts are contracted, acquaintances begun about a green table, and by quarrels in which life or honour comes to grief, and though one may be an honest man, one finds oneself ruined by very honest men, whose only defect is that they have not two hundred thousand francs a year. I need not tell you of those who cheat at play. I flung myself into this rapid, noisy, and volcanic life, which had formerly terrified me when I thought of it, and which had become for me the necessary complement of my love for Marguerite. What else could I have done? The nights that I did not spend in the Rue d'Antin, if I had spent them alone in my own room, I could not have slept. Jealousy would have kept me awake, and inflamed my blood and my thoughts.\"}\n"
     ]
    }
   ],
   "source": [
    "# let's check our transcription - looks spot on!\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's step it up a notch. Let's try transcribing 30 minutes of audio from the LibriSpeech dataset. We'll first load up and listen to the second sample from our dataset, which corresponds to the 30 min audio file. We'll then pass the audio to the model for transcription, again timing how long the foward pass takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = test_dataset[1][\"audio\"]  # load the second sample (30 mins) and get the audio array\n",
    "\n",
    "Audio(audio[\"array\"], rate=audio[\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 3min 56s, total: 5min 8s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "# transcribe using cached function\n",
    "%time text = pipeline(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just 14s to transcribe for 30 mins of audio! That means you could transcribe an entire 2 hour movie in under 1 minute 🤯 By increasing the batch size, we could also reduce the transcription time for long audio files further: increasing the batch size by 2x roughly decreases the transcription time by 2x, provided the overall batch size is less than the total audio time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⏰ Timestamps and more\n",
    "\n",
    "We can also get timestamps from the model by passing `return_timestamps=True`, but this will require a recompilation since we change the signature of the forward pass. \n",
    "\n",
    "The timestamps compilation takes longer than the non-timestamps one. Luckily, because we initialised our compilation cache above, we're not starting from scratch in compiling this time. This is the last compilation we need to do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 34s, sys: 10min 38s, total: 16min 12s\n",
      "Wall time: 1min 55s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext = pipeline(audio, return_timestamps=True)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# transcription\u001b[39;00m\n\u001b[1;32m      3\u001b[0m chunks \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunks\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# transcription + timestamps\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "%time outputs = pipeline(audio, return_timestamps=True)\n",
    "text = outputs[\"text\"]  # transcription\n",
    "chunks = outputs[\"chunks\"]  # transcription + timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've shown how you can transcibe an audio file in English. The pipeline is also compatible with two further arguments that you can use to control the generation process. It's perfectly fine to omit these if you want speech transcription and the Whisper model to automatically detect which language the audio is in. Otherwise, you can change them depending on your task/language:\n",
    "\n",
    "\n",
    "* `task`: task to use for generation, either `\"transcribe\"` or `\"translate\"`. Defaults to `\"transcribe\"`.\n",
    "* `language`: language token to use for generation, can be either in the form of `\"<|en|>\"`, `\"en\"` or `\"english\"`. Defaults to `None`, meaning the language is automatically inferred from the audio input. Optional, and only relevant if the source audio language is known a-priori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
