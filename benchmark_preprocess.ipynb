{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7f1cf1-b9e5-424b-b0f9-f2932fb81534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanchitgandhi/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, WhisperFeatureExtractor\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922e6a8a-96e5-427a-821c-6db672119582",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "\n",
    "feature_extractor = processor.feature_extractor\n",
    "tokenizer = processor.tokenizer\n",
    "\n",
    "audio_column_name = \"audio\"\n",
    "model_input_name = \"input_features\"\n",
    "train_text_column_name = \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20de44fe-8b89-43be-b908-5f7576eca41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "raw_dataset_features = list(raw_dataset.features.keys())\n",
    "\n",
    "raw_dataset = raw_dataset.select(range(50 // 2))\n",
    "raw_dataset = concatenate_datasets([raw_dataset for _ in range(2 * 50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f295866-07b7-4d89-8f10-e16ed5b11bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # process audio\n",
    "    sample = batch[audio_column_name]\n",
    "    inputs = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"np\")\n",
    "\n",
    "    # process audio length\n",
    "    batch[model_input_name] = inputs.get(model_input_name)[0]\n",
    "    batch[\"input_length\"] = len(sample[\"array\"])\n",
    "\n",
    "    # process targets\n",
    "    input_str = batch[train_text_column_name]\n",
    "    batch[\"labels\"] = tokenizer(input_str).input_ids\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10073533-e228-4dc6-9712-9a7268edbba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████| 2500/2500 [01:36<00:00, 25.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vectorized_dataset = raw_dataset.map(prepare_dataset, remove_columns=raw_dataset_features, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "535ab307-3c1f-458c-912b-6a22316b9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchWhisperFeatureExtractor(WhisperFeatureExtractor):\n",
    "    def _np_extract_fbank_features(self, waveform: np.array) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute the log-mel spectrogram of the provided audio using torch filters. \n",
    "        \"\"\"\n",
    "        waveform = torch.from_numpy(waveform).type(torch.float32)\n",
    "\n",
    "        window = torch.hann_window(self.n_fft)\n",
    "        stft = torch.stft(waveform, self.n_fft, self.hop_length, window=window, return_complex=True)\n",
    "        magnitudes = stft[..., :-1].abs() ** 2\n",
    "\n",
    "        mel_filters = torch.from_numpy(self.mel_filters).type(torch.float32)\n",
    "        mel_spec = mel_filters.T @ magnitudes\n",
    "\n",
    "        log_spec = torch.clamp(mel_spec, min=1e-10).log10()\n",
    "        log_spec = torch.maximum(log_spec, log_spec.max() - 8.0)\n",
    "        log_spec = (log_spec + 4.0) / 4.0\n",
    "        return log_spec.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71bd96b9-4d0b-42cb-ab34-2cc7539085b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_feature_extractor = TorchWhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c28076fc-c67a-487f-940a-4060c81dd26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_torch_dataset(batch):\n",
    "    # process audio\n",
    "    sample = batch[audio_column_name]\n",
    "    inputs = flax_feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"np\")\n",
    "\n",
    "    # process audio length\n",
    "    batch[model_input_name] = inputs.get(model_input_name)[0]\n",
    "    batch[\"input_length\"] = len(sample[\"array\"])\n",
    "\n",
    "    # process targets\n",
    "    input_str = batch[train_text_column_name]\n",
    "    batch[\"labels\"] = tokenizer(input_str).input_ids\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95b5bc8c-c49f-416c-a1aa-004bbaf401b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████| 2500/2500 [00:23<00:00, 105.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vectorized_torch_dataset = raw_dataset.map(prepare_torch_dataset, remove_columns=raw_dataset_features, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b44720f-d282-454a-b55d-2a79c56b2ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.58306884765625e-06"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(np.array(vectorized_torch_dataset[0][\"input_features\"]) - np.array(vectorized_dataset[0][\"input_features\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485e223-3f5c-4673-9ace-51dfadf323f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
